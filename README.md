# Deepest Task

## Question3 Kaggle - CommonLit Readability Prize

### Submission
(TBD)

### Run
(TBD)

### Solution
- RoBERTa
- Pre-trained Model
- LP-FT

### Loss Graph
(TBD)

### References
- [RoBERTa Paper](https://arxiv.org/abs/1907.11692)
- [LP-FT Paper](https://arxiv.org/abs/2202.10054)
- [Pre-trained RoBERTa Kaggle Notebook](https://www.kaggle.com/code/andretugan/pre-trained-roberta-solution-in-pytorch/notebook)
